{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Non feature\n",
    "NON_FEATURE=['activity_id','people_id','date','people_date']\n",
    "\n",
    "# Categorical data that is only label encoded\n",
    "CATEGORICAL_DATA = ['people_char_1', 'people_char_2','people_group_1',\n",
    "                    'people_char_3', 'people_char_4', 'people_char_5',\n",
    "                    'people_char_6', 'people_char_7', 'people_char_8',\n",
    "                    'people_char_9', 'activity_category',\n",
    "                    'char_1', 'char_2', 'char_3', 'char_4', 'char_5', 'char_6',\n",
    "                    'char_7', 'char_8', 'char_9']\n",
    "\n",
    "#removed char_10 to check xgb\n",
    "\n",
    "# Already in a one-hot encoded form\n",
    "CATEGORICAL_BINARY = ['people_char_10', 'people_char_11', 'people_char_12',\n",
    "                      'people_char_13', 'people_char_14', 'people_char_15',\n",
    "                      'people_char_16', 'people_char_17', 'people_char_18',\n",
    "                      'people_char_19', 'people_char_20', 'people_char_21',\n",
    "                      'people_char_22', 'people_char_23', 'people_char_24',\n",
    "                      'people_char_25', 'people_char_26', 'people_char_27',\n",
    "                      'people_char_28', 'people_char_29', 'people_char_30',\n",
    "                      'people_char_31', 'people_char_32', 'people_char_33',\n",
    "                      'people_char_34', 'people_char_35', 'people_char_36',\n",
    "                      'people_char_37' ]\n",
    "\n",
    "# Continuous categories\n",
    "CONT = ['people_days', 'days',\n",
    "        'people_month',  'month',\n",
    "        'people_quarter', 'quarter',\n",
    "        'people_week', 'week',\n",
    "        'people_dayOfMonth', 'dayOfMonth',\n",
    "        'people_year', 'year',\n",
    "        'people_char_38']\n",
    "\n",
    "\n",
    "# Path to people.csv from ReadHat Kaggle data set with reduced dimensions\n",
    "FEATURE_FILE ='Data/act_train_features_reduced.csv'\n",
    "# Path to act_train.csv from RedHat Kaggle data set with reduced dimensions\n",
    "OUTPUT ='Data/act_train_output.csv'\n",
    "\n",
    "TEST_FILE = 'Data/act_test_features_reduced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def category_to_one_hot(dataset, non_feature, continuous_feature):\n",
    "    # Function to change labels of categories to one-hot encoding using scikit's OneHot Encoding sparse matrix\n",
    "    # pd.get_dummies(df) does the same, provides sweet header's as well but it kill's memory\n",
    "    ds = dataset.drop(non_feature, axis=1)\n",
    "    boolean_column = []\n",
    "    counter = 0\n",
    "    for column in ds.columns:\n",
    "        if column not in continuous_feature:\n",
    "            boolean_column.append(counter)\n",
    "        counter += 1\n",
    "    # boolean_column is not the column name but index\n",
    "    print(\"Done filtering columns...\")\n",
    "    grd_enc = OneHotEncoder(categorical_features=boolean_column)\n",
    "    encoded_arr = grd_enc.fit_transform(ds)\n",
    "    return encoded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the data set. Note this dataset does not contain the 'outcome' columns\n",
    "train_data_df = pd.read_csv(FEATURE_FILE,parse_dates=[\"date\"])\n",
    "train_data_df.sort_values(by=['activity_id'],ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "# Read the train data output\n",
    "train_output = pd.read_csv(OUTPUT)\n",
    "train_output.sort_values(by='activity_id',ascending=True, inplace=True)\n",
    "v_out=train_output['outcome'].as_matrix()\n",
    "\n",
    "test_data_df = pd.read_csv(TEST_FILE,parse_dates=[\"date\"])\n",
    "test_data_df.sort_values(by=['activity_id'],ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NON_FEATURES=[]\n",
    "#for column in data_df.columns:\n",
    "#    if column not in SELECTED_FEATURES:\n",
    "#        NON_FEATURES.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################ UNTOUCHED ######################################\n",
    "def normalize(df,non_features):\n",
    "    df=df.drop(non_features,axis=1)\n",
    "    features=df.columns\n",
    "    # Normalize categorical values to range betwwen 0-1, time usually : 3secs\n",
    "    start=time.time()\n",
    "    scaler = Normalizer()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    end = time.time()\n",
    "    print (end-start)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try random forest + linear regression\n",
    "# forest_data=data_df[[ 'people_group_1']].as_matrix()\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_data_df,v_out, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done filtering columns...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "set_index not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-604f9e814302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## SAMPLE: without dropping char_10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNON_FEATURE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activity_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"act_train_features_onehot.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m## SAMPLE: try to run with char_10 first, if it does crash, you add it in NON_FEATURE and then run this code. Okay?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: set_index not found"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "## SAMPLE: without dropping char_10\n",
    "train_arr = category_to_one_hot(train_data_df, NON_FEATURE, CONT)\n",
    "#train_arr.set_index(['activity_id']).to_csv(\"act_train_features_onehot.csv\")\n",
    "## SAMPLE: try to run with char_10 first, if it does crash, you add it in NON_FEATURE and then run this code. Okay?\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done filtering columns...\n",
      "15.6170809269\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "## SAMPLE: without dropping char_10\n",
    "test_arr = category_to_one_hot(test_data_df, NON_FEATURE, CONT)\n",
    "## SAMPLE: try to run with char_10 first, if it does crash, you add it in NON_FEATURE and then run this code. Okay?\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scal=Normalizer()\n",
    "arr_train_norm=scal.fit_transform(train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scal=Normalizer()\n",
    "arr_test_norm=scal.fit_transform(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.3, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=0, missing=None, n_estimators=25, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=1, subsample=0.7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(max_depth=10, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='binary:logistic', subsample=0.7,\n",
    "                    colsample_bytree=0.7, seed=0, silent=1, nthread=4,\n",
    "                    min_child_weight=0)\n",
    "\n",
    "watchlist  = [(arr_train_norm,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "\n",
    "#bst = xgb.train(param, arr_train_norm, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "xgb.fit(arr_train_norm, v_out,eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.849711\n",
      "Will train until train-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.856853\n",
      "[2]\ttrain-auc:0.864064\n",
      "[3]\ttrain-auc:0.87173\n",
      "[4]\ttrain-auc:0.880292\n",
      "[5]\ttrain-auc:0.889228\n",
      "[6]\ttrain-auc:0.897624\n",
      "[7]\ttrain-auc:0.905135\n",
      "[8]\ttrain-auc:0.911837\n",
      "[9]\ttrain-auc:0.917867\n",
      "[10]\ttrain-auc:0.923282\n",
      "[11]\ttrain-auc:0.92811\n",
      "[12]\ttrain-auc:0.932371\n",
      "[13]\ttrain-auc:0.936119\n",
      "[14]\ttrain-auc:0.939419\n",
      "[15]\ttrain-auc:0.942329\n",
      "[16]\ttrain-auc:0.944907\n",
      "[17]\ttrain-auc:0.947196\n",
      "[18]\ttrain-auc:0.949237\n",
      "[19]\ttrain-auc:0.95107\n",
      "[20]\ttrain-auc:0.952724\n",
      "[21]\ttrain-auc:0.95422\n",
      "[22]\ttrain-auc:0.955581\n",
      "[23]\ttrain-auc:0.956822\n",
      "[24]\ttrain-auc:0.957959\n",
      "[25]\ttrain-auc:0.959005\n",
      "[26]\ttrain-auc:0.959967\n",
      "[27]\ttrain-auc:0.960851\n",
      "[28]\ttrain-auc:0.961668\n",
      "[29]\ttrain-auc:0.962422\n",
      "[30]\ttrain-auc:0.96312\n",
      "[31]\ttrain-auc:0.963767\n",
      "[32]\ttrain-auc:0.964365\n",
      "[33]\ttrain-auc:0.964922\n",
      "[34]\ttrain-auc:0.965438\n",
      "[35]\ttrain-auc:0.965916\n",
      "[36]\ttrain-auc:0.966359\n",
      "[37]\ttrain-auc:0.966769\n",
      "[38]\ttrain-auc:0.967152\n",
      "[39]\ttrain-auc:0.967509\n",
      "[40]\ttrain-auc:0.967839\n",
      "[41]\ttrain-auc:0.968145\n",
      "[42]\ttrain-auc:0.96843\n",
      "[43]\ttrain-auc:0.968695\n",
      "[44]\ttrain-auc:0.968942\n",
      "[45]\ttrain-auc:0.969173\n",
      "[46]\ttrain-auc:0.969389\n",
      "[47]\ttrain-auc:0.969591\n",
      "[48]\ttrain-auc:0.96978\n",
      "[49]\ttrain-auc:0.969958\n",
      "[50]\ttrain-auc:0.970125\n",
      "[51]\ttrain-auc:0.970282\n",
      "[52]\ttrain-auc:0.970431\n",
      "[53]\ttrain-auc:0.970572\n",
      "[54]\ttrain-auc:0.970706\n",
      "[55]\ttrain-auc:0.970834\n",
      "[56]\ttrain-auc:0.970956\n",
      "[57]\ttrain-auc:0.971072\n",
      "[58]\ttrain-auc:0.971183\n",
      "[59]\ttrain-auc:0.97129\n",
      "[60]\ttrain-auc:0.971392\n",
      "[61]\ttrain-auc:0.97149\n",
      "[62]\ttrain-auc:0.971584\n",
      "[63]\ttrain-auc:0.971675\n",
      "[64]\ttrain-auc:0.971762\n",
      "[65]\ttrain-auc:0.971846\n",
      "[66]\ttrain-auc:0.971928\n",
      "[67]\ttrain-auc:0.972006\n",
      "[68]\ttrain-auc:0.972082\n",
      "[69]\ttrain-auc:0.972156\n",
      "[70]\ttrain-auc:0.972227\n",
      "[71]\ttrain-auc:0.972295\n",
      "[72]\ttrain-auc:0.972362\n",
      "[73]\ttrain-auc:0.972427\n",
      "[74]\ttrain-auc:0.97249\n",
      "[75]\ttrain-auc:0.972551\n",
      "[76]\ttrain-auc:0.97261\n",
      "[77]\ttrain-auc:0.972667\n",
      "[78]\ttrain-auc:0.972724\n",
      "[79]\ttrain-auc:0.972779\n",
      "[80]\ttrain-auc:0.972832\n",
      "[81]\ttrain-auc:0.972884\n",
      "[82]\ttrain-auc:0.972935\n",
      "[83]\ttrain-auc:0.972985\n",
      "[84]\ttrain-auc:0.973033\n",
      "[85]\ttrain-auc:0.97308\n",
      "[86]\ttrain-auc:0.973127\n",
      "[87]\ttrain-auc:0.973172\n",
      "[88]\ttrain-auc:0.973216\n",
      "[89]\ttrain-auc:0.973259\n",
      "[90]\ttrain-auc:0.973302\n",
      "[91]\ttrain-auc:0.973343\n",
      "[92]\ttrain-auc:0.973384\n",
      "[93]\ttrain-auc:0.973423\n",
      "[94]\ttrain-auc:0.973462\n",
      "[95]\ttrain-auc:0.973501\n",
      "[96]\ttrain-auc:0.973538\n",
      "[97]\ttrain-auc:0.973574\n",
      "[98]\ttrain-auc:0.97361\n",
      "[99]\ttrain-auc:0.973645\n",
      "[100]\ttrain-auc:0.97368\n",
      "[101]\ttrain-auc:0.973714\n",
      "[102]\ttrain-auc:0.973747\n",
      "[103]\ttrain-auc:0.97378\n",
      "[104]\ttrain-auc:0.973812\n",
      "[105]\ttrain-auc:0.973843\n",
      "[106]\ttrain-auc:0.973874\n",
      "[107]\ttrain-auc:0.973904\n",
      "[108]\ttrain-auc:0.973934\n",
      "[109]\ttrain-auc:0.973963\n",
      "[110]\ttrain-auc:0.973992\n",
      "[111]\ttrain-auc:0.97402\n",
      "[112]\ttrain-auc:0.974047\n",
      "[113]\ttrain-auc:0.974074\n",
      "[114]\ttrain-auc:0.974101\n",
      "[115]\ttrain-auc:0.974127\n",
      "[116]\ttrain-auc:0.974153\n",
      "[117]\ttrain-auc:0.974178\n",
      "[118]\ttrain-auc:0.974203\n",
      "[119]\ttrain-auc:0.974228\n",
      "[120]\ttrain-auc:0.974252\n",
      "[121]\ttrain-auc:0.974275\n",
      "[122]\ttrain-auc:0.974298\n",
      "[123]\ttrain-auc:0.974321\n",
      "[124]\ttrain-auc:0.974344\n",
      "[125]\ttrain-auc:0.974366\n",
      "[126]\ttrain-auc:0.974388\n",
      "[127]\ttrain-auc:0.974409\n",
      "[128]\ttrain-auc:0.97443\n",
      "[129]\ttrain-auc:0.97445\n",
      "[130]\ttrain-auc:0.974471\n",
      "[131]\ttrain-auc:0.974491\n",
      "[132]\ttrain-auc:0.97451\n",
      "[133]\ttrain-auc:0.97453\n",
      "[134]\ttrain-auc:0.974549\n",
      "[135]\ttrain-auc:0.974567\n",
      "[136]\ttrain-auc:0.974586\n",
      "[137]\ttrain-auc:0.974604\n",
      "[138]\ttrain-auc:0.974622\n",
      "[139]\ttrain-auc:0.974639\n",
      "[140]\ttrain-auc:0.974657\n",
      "[141]\ttrain-auc:0.974673\n",
      "[142]\ttrain-auc:0.97469\n",
      "[143]\ttrain-auc:0.974706\n",
      "[144]\ttrain-auc:0.974722\n",
      "[145]\ttrain-auc:0.974738\n",
      "[146]\ttrain-auc:0.974754\n",
      "[147]\ttrain-auc:0.974769\n",
      "[148]\ttrain-auc:0.974784\n",
      "[149]\ttrain-auc:0.974799\n",
      "[150]\ttrain-auc:0.974813\n",
      "[151]\ttrain-auc:0.974828\n",
      "[152]\ttrain-auc:0.974842\n",
      "[153]\ttrain-auc:0.974856\n",
      "[154]\ttrain-auc:0.974869\n",
      "[155]\ttrain-auc:0.974883\n",
      "[156]\ttrain-auc:0.974896\n",
      "[157]\ttrain-auc:0.974909\n",
      "[158]\ttrain-auc:0.974922\n",
      "[159]\ttrain-auc:0.974935\n",
      "[160]\ttrain-auc:0.974948\n",
      "[161]\ttrain-auc:0.97496\n",
      "[162]\ttrain-auc:0.974972\n",
      "[163]\ttrain-auc:0.974984\n",
      "[164]\ttrain-auc:0.974996\n",
      "[165]\ttrain-auc:0.975007\n",
      "[166]\ttrain-auc:0.975019\n",
      "[167]\ttrain-auc:0.97503\n",
      "[168]\ttrain-auc:0.975041\n",
      "[169]\ttrain-auc:0.975052\n",
      "[170]\ttrain-auc:0.975063\n",
      "[171]\ttrain-auc:0.975073\n",
      "[172]\ttrain-auc:0.975084\n",
      "[173]\ttrain-auc:0.975094\n",
      "[174]\ttrain-auc:0.975104\n",
      "[175]\ttrain-auc:0.975114\n",
      "[176]\ttrain-auc:0.975124\n",
      "[177]\ttrain-auc:0.975133\n",
      "[178]\ttrain-auc:0.975143\n",
      "[179]\ttrain-auc:0.975152\n",
      "[180]\ttrain-auc:0.975162\n",
      "[181]\ttrain-auc:0.975171\n",
      "[182]\ttrain-auc:0.97518\n",
      "[183]\ttrain-auc:0.975189\n",
      "[184]\ttrain-auc:0.975197\n",
      "[185]\ttrain-auc:0.975206\n",
      "[186]\ttrain-auc:0.975214\n",
      "[187]\ttrain-auc:0.975223\n",
      "[188]\ttrain-auc:0.975231\n",
      "[189]\ttrain-auc:0.975239\n",
      "[190]\ttrain-auc:0.975247\n",
      "[191]\ttrain-auc:0.975255\n",
      "[192]\ttrain-auc:0.975263\n",
      "[193]\ttrain-auc:0.97527\n",
      "[194]\ttrain-auc:0.975278\n",
      "[195]\ttrain-auc:0.975285\n",
      "[196]\ttrain-auc:0.975293\n",
      "[197]\ttrain-auc:0.9753\n",
      "[198]\ttrain-auc:0.975307\n",
      "[199]\ttrain-auc:0.975314\n",
      "[200]\ttrain-auc:0.975321\n",
      "[201]\ttrain-auc:0.975327\n",
      "[202]\ttrain-auc:0.975334\n",
      "[203]\ttrain-auc:0.975341\n",
      "[204]\ttrain-auc:0.975347\n",
      "[205]\ttrain-auc:0.975354\n",
      "[206]\ttrain-auc:0.97536\n",
      "[207]\ttrain-auc:0.975366\n",
      "[208]\ttrain-auc:0.975372\n",
      "[209]\ttrain-auc:0.975378\n",
      "[210]\ttrain-auc:0.975384\n",
      "[211]\ttrain-auc:0.97539\n",
      "[212]\ttrain-auc:0.975396\n",
      "[213]\ttrain-auc:0.975402\n",
      "[214]\ttrain-auc:0.975407\n",
      "[215]\ttrain-auc:0.975413\n",
      "[216]\ttrain-auc:0.975418\n",
      "[217]\ttrain-auc:0.975424\n",
      "[218]\ttrain-auc:0.975429\n",
      "[219]\ttrain-auc:0.975434\n",
      "[220]\ttrain-auc:0.97544\n",
      "[221]\ttrain-auc:0.975445\n",
      "[222]\ttrain-auc:0.97545\n",
      "[223]\ttrain-auc:0.975455\n",
      "[224]\ttrain-auc:0.97546\n",
      "[225]\ttrain-auc:0.975465\n",
      "[226]\ttrain-auc:0.975469\n",
      "[227]\ttrain-auc:0.975474\n",
      "[228]\ttrain-auc:0.975479\n",
      "[229]\ttrain-auc:0.975483\n",
      "[230]\ttrain-auc:0.975488\n",
      "[231]\ttrain-auc:0.975492\n",
      "[232]\ttrain-auc:0.975497\n",
      "[233]\ttrain-auc:0.975501\n",
      "[234]\ttrain-auc:0.975505\n",
      "[235]\ttrain-auc:0.975509\n",
      "[236]\ttrain-auc:0.975513\n",
      "[237]\ttrain-auc:0.975518\n",
      "[238]\ttrain-auc:0.975522\n",
      "[239]\ttrain-auc:0.975526\n",
      "[240]\ttrain-auc:0.975529\n",
      "[241]\ttrain-auc:0.975533\n",
      "[242]\ttrain-auc:0.975537\n",
      "[243]\ttrain-auc:0.975541\n",
      "[244]\ttrain-auc:0.975545\n",
      "[245]\ttrain-auc:0.975549\n",
      "[246]\ttrain-auc:0.975552\n",
      "[247]\ttrain-auc:0.975556\n",
      "[248]\ttrain-auc:0.975559\n",
      "[249]\ttrain-auc:0.975563\n",
      "[250]\ttrain-auc:0.975566\n",
      "[251]\ttrain-auc:0.97557\n",
      "[252]\ttrain-auc:0.975573\n",
      "[253]\ttrain-auc:0.975576\n",
      "[254]\ttrain-auc:0.975579\n",
      "[255]\ttrain-auc:0.975583\n",
      "[256]\ttrain-auc:0.975586\n",
      "[257]\ttrain-auc:0.975589\n",
      "[258]\ttrain-auc:0.975592\n",
      "[259]\ttrain-auc:0.975595\n",
      "[260]\ttrain-auc:0.975598\n",
      "[261]\ttrain-auc:0.975601\n",
      "[262]\ttrain-auc:0.975604\n",
      "[263]\ttrain-auc:0.975607\n",
      "[264]\ttrain-auc:0.97561\n",
      "[265]\ttrain-auc:0.975613\n",
      "[266]\ttrain-auc:0.975616\n",
      "[267]\ttrain-auc:0.975618\n",
      "[268]\ttrain-auc:0.975621\n",
      "[269]\ttrain-auc:0.975624\n",
      "[270]\ttrain-auc:0.975627\n",
      "[271]\ttrain-auc:0.975629\n",
      "[272]\ttrain-auc:0.975632\n",
      "[273]\ttrain-auc:0.975635\n",
      "[274]\ttrain-auc:0.975637\n",
      "[275]\ttrain-auc:0.97564\n",
      "[276]\ttrain-auc:0.975642\n",
      "[277]\ttrain-auc:0.975645\n",
      "[278]\ttrain-auc:0.975647\n",
      "[279]\ttrain-auc:0.97565\n",
      "[280]\ttrain-auc:0.975652\n",
      "[281]\ttrain-auc:0.975654\n",
      "[282]\ttrain-auc:0.975657\n",
      "[283]\ttrain-auc:0.975659\n",
      "[284]\ttrain-auc:0.975661\n",
      "[285]\ttrain-auc:0.975663\n",
      "[286]\ttrain-auc:0.975665\n",
      "[287]\ttrain-auc:0.975668\n",
      "[288]\ttrain-auc:0.97567\n",
      "[289]\ttrain-auc:0.975672\n",
      "[290]\ttrain-auc:0.975674\n",
      "[291]\ttrain-auc:0.975676\n",
      "[292]\ttrain-auc:0.975678\n",
      "[293]\ttrain-auc:0.97568\n",
      "[294]\ttrain-auc:0.975682\n",
      "[295]\ttrain-auc:0.975684\n",
      "[296]\ttrain-auc:0.975686\n",
      "[297]\ttrain-auc:0.975688\n",
      "[298]\ttrain-auc:0.97569\n",
      "[299]\ttrain-auc:0.975692\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-15c13da6d8a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'activity_id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activity_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outcome'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'without_leak.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "#Trial. Run instead of above three \n",
    "dtrain = xgb.DMatrix(train_arr,label=v_out)\n",
    "dtest = xgb.DMatrix(test_arr)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.7\n",
    "param['min_child_weight'] = 0\n",
    "param['booster'] = \"gblinear\"\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({ 'activity_id' : test_data_df['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#y_pred = xgb.predict(arr_test_norm)\n",
    "#predictions = [round(value) for value in y_pred]\n",
    "\n",
    "#For predicting probability for final kaggle outcome\n",
    "#predictions = bst.predict(arr_test_norm)\n",
    "predictions = xgb.predict_proba(arr_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('feature_importance_xgb' + '.txt',\n",
    "           xgb.feature_importances_, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_df['outcome']=predictions[:,1]\n",
    "\n",
    "test_data_df[['outcome','activity_id']].set_index('activity_id').drop('act_0').to_csv(\"XGBOOST_results.csv\")\n",
    "\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# evaluate predictions\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
