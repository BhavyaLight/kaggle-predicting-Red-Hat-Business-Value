{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to people.csv from ReadHatKaggle data set\n",
    "PEOPLE_FILE_PATH='../people.csv'\n",
    "# Path to act_train.csv from RedHatKaggle data set\n",
    "ACTIVITIES_FILE_PATH='../act_train.csv'\n",
    "# Path to test.csv from RedHatKaggle data set\n",
    "TEST_DATA_FILE_PATH='../act_test.csv'\n",
    "\n",
    "# For enabling one hot key encoding\n",
    "ONE_HOT_KEY = True\n",
    "\n",
    "# Columns that do not represent features\n",
    "# TODO: date is not a NON-FEATURE, right now the preprocessing for date has not been done\n",
    "NON_FEATURE=['people_people_id','people_id','activity_id','outcome','people_date','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to change labels of  categories to an encoding value\n",
    "# By default all 'id' columns are not regarded as features and not encoded\n",
    "# however, identity_columns parameter can be changed according to requirement\n",
    "def category_to_label_encoding(dataset,identity_columns=['people_people_id','people_id','activity_id']):\n",
    "    for column in dataset.columns:\n",
    "        if column not in identity_columns:\n",
    "            if (dataset[column].dtype == 'O'):\n",
    "                dataset[column]=dataset[column].apply(lambda x: str(x).split(' ')[1]).astype(np.int32)\n",
    "              # Not sure right now if we need this or sckit will treat boolean as integer vales only\n",
    "#           elif dataset[column].dtype == 'bool':\n",
    "#                 le=LabelEncoder()\n",
    "#                 le.fit(['True','False'])\n",
    "#                 dataset[column]=le.transform(dataset[column])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fubction to change labels of categories to one-hot encoding\n",
    "# While pd.get_dummies provied easier header labelling, it's really killing memory\n",
    "def category_to_one_hot(dataset,non_feature=NON_FEATURE):\n",
    "    boolean_column = []\n",
    "#     column_names = []\n",
    "    counter=0\n",
    "    for column in dataset.columns:\n",
    "        if column not in NON_FEATURE:\n",
    "            if dataset[column].dtype == 'bool':\n",
    "                counter += 1\n",
    "                continue\n",
    "            if dataset[column].dtype == '<M8[ns]':\n",
    "                counter += 1\n",
    "                continue\n",
    "            boolean_column.append(counter)\n",
    "#             column_names.append(column)\n",
    "            counter += 1\n",
    "    ds = dataset.drop(NON_FEATURE, axis=1)\n",
    "    grd_enc = OneHotEncoder(categorical_features=boolean_column)\n",
    "    encoded_arr=grd_enc.fit_transform(ds).toarray()\n",
    "    return encoded_arr,grd_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the data set's\n",
    "people_df=pd.read_csv(PEOPLE_FILE_PATH,parse_dates=[\"date\"],true_values=[\"True\"],false_values=[\"False\"])\n",
    "activity_df=pd.read_csv(ACTIVITIES_FILE_PATH, parse_dates=[\"date\"])\n",
    "test_df=pd.read_csv(TEST_DATA_FILE_PATH,parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introduce a category for null values called category 0 since scikit needs numeric data\n",
    "people_df.fillna(\"type 0\", inplace=True)\n",
    "activity_df.fillna(\"type 0\", inplace=True)\n",
    "test_df.fillna(\"type 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns under people_df to avoid same-names in the three dataframe\n",
    "people_df = people_df.rename(columns=lambda x : \"people_\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge activity and test data frame with people_df\n",
    "train_dataset = pd.merge(people_df, activity_df, how='right', left_on='people_people_id', right_on=\"people_id\")\n",
    "test_dataset = pd.merge(people_df, activity_df, how='right', left_on='people_people_id', right_on=\"people_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clearing memory\n",
    "del people_df\n",
    "del activity_df\n",
    "del test_df\n",
    "\n",
    "# Not using the official label encoder because it is beneficial to have type 7 -> 7\n",
    "# The label encoder might assign 6 to type 7 based on when it appears  in the list\n",
    "# Sorting might improve it but sometimes values are missing from the type\n",
    "train_dataset = category_to_label_encoding(train_dataset)\n",
    "test_dataset = category_to_label_encoding(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...,  1.  1.  0.]\n",
      " [ 0.  1.  0. ...,  1.  1.  0.]\n",
      " [ 0.  1.  0. ...,  1.  1.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  1.  1.  1.]\n",
      " [ 0.  1.  0. ...,  1.  1.  1.]\n",
      " [ 0.  1.  0. ...,  1.  1.  1.]]\n",
      "[    1     2     4 ..., 61124 61128 61132]\n",
      "[    3 51463     4    45    26    10     8    26     9    10   101     8\n",
      "    53    33    12     8     8     6     9    19    20  9252]\n",
      "[    0     3 51466 51470 51515 51541 51551 51559 51585 51594 51604 51705\n",
      " 51713 51766 51799 51811 51819 51827 51833 51842 51861 51881 61133]\n"
     ]
    }
   ],
   "source": [
    "# for train_dataset\n",
    "dataset = train_dataset\n",
    "if ONE_HOT_KEY:\n",
    "    encoded_array, grd_enc=category_to_one_hot(dataset)\n",
    "    print (encoded_array)\n",
    "    # TODO: NOT SURE HOW WE FIND OUT THE LABEL NAMES OR IF THEY EVEN MATTER\n",
    "    print (grd_enc.active_features_)\n",
    "    print (grd_enc.n_values_)\n",
    "    print (grd_enc.feature_indices_)\n",
    "else:\n",
    "    numeric_headers = list(dataset.drop(NON_FEATURE, axis=1).columns.values)\n",
    "    numpy_array = dataset.drop(NON_FEATURE, axis=1).as_matrix()\n",
    "    print (numpy_array)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
